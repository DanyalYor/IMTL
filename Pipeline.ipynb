{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1553cb2f",
   "metadata": {},
   "source": [
    "# Settings script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_1 = True\n",
    "MODEL_2 = False\n",
    "\n",
    "RUN_RAYTUNE = True\n",
    "USE_FULL_DATASET = False  # If false, use small dataset instead (10K pictures, 100 per class)\n",
    "\n",
    "# Ensure exactly one model is selected\n",
    "assert sum([MODEL_1, MODEL_2]) == 1, \"Exactly one model must be selected.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56810e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pathlib\n",
    "\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from tqdm import tqdm\n",
    "\n",
    "# RayTune imports (safe even if not used)\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d11ed7",
   "metadata": {},
   "source": [
    "# Set GPU variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f85172",
   "metadata": {},
   "source": [
    "# Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223add30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = pathlib.Path().resolve()\n",
    "\n",
    "if USE_FULL_DATASET:\n",
    "    IMAGE_DIR = ROOT / \"data\" / \"archive\" / \"food-101\" / \"food-101\" / \"images\"\n",
    "else:\n",
    "    IMAGE_DIR = ROOT / \"data\" / \"food-101-small\"\n",
    "\n",
    "print(\"Using IMAGE_DIR =\", IMAGE_DIR)\n",
    "\n",
    "if not IMAGE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Missing dataset folder:\\n{IMAGE_DIR}\")\n",
    "\n",
    "# Safety: avoid __MACOSX folders\n",
    "bad_paths = list((ROOT / \"data\" / \"archive\" / \"food-101\").rglob(\"__MACOSX\"))\n",
    "if bad_paths:\n",
    "    print(\"⚠ WARNING: __MACOSX folders detected.\")\n",
    "\n",
    "print(\"Dataset path OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338636e",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(IMAGE_DIR, transform=train_transform, allow_empty=True)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Total images:\", len(full_dataset))\n",
    "print(\"Classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc7548",
   "metadata": {},
   "source": [
    "# Split data into sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3477ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size   = int(0.2 * len(full_dataset))\n",
    "test_size  = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(full_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a56d32",
   "metadata": {},
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds.dataset.transform = test_transform\n",
    "test_ds.dataset.transform = test_transform\n",
    "\n",
    "batch_size_default = 32\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size_default, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size_default, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size_default, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db9857",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1(lr, num_classes):\n",
    "    \"\"\"EfficientNet-B0 model\"\"\"\n",
    "    weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "    model = efficientnet_b0(weights=weights)\n",
    "\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, optimizer, criterion\n",
    "\n",
    "\n",
    "def build_model_2(lr, num_classes):\n",
    "    \"\"\"Placeholder model — intentionally blank\"\"\"\n",
    "    raise NotImplementedError(\"MODEL_2 not implemented yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9727ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_1:\n",
    "    build_model = build_model_1\n",
    "elif MODEL_2:\n",
    "    build_model = build_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b997e6e",
   "metadata": {},
   "source": [
    "# Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d527f",
   "metadata": {},
   "source": [
    "# Define Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_train(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    # local transforms\n",
    "    train_ds.dataset.transform = train_transform\n",
    "    val_ds.dataset.transform   = test_transform\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    model, optimizer, criterion = build_model(lr, num_classes)\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        tune.report({\"loss\": float(val_loss), \"accuracy\": float(val_acc)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0464e41",
   "metadata": {},
   "source": [
    "# Run RayTune (If toggled on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_RAYTUNE:\n",
    "    os.environ[\"RAY_DISABLE_METRICS_EXPORT\"] = \"1\"\n",
    "\n",
    "    search_space = {\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"batch_size\": tune.choice([16, 32, 64]),\n",
    "        \"epochs\": 3\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(metric=\"accuracy\", mode=\"max\")\n",
    "    reporter  = CLIReporter(metric_columns=[\"loss\", \"accuracy\"])\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune_train,\n",
    "            resources={\"cpu\": 4, \"gpu\": 1 if torch.cuda.is_available() else 0},\n",
    "        ),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=6,\n",
    "        ),\n",
    "        run_config=tune.RunConfig(progress_reporter=reporter),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"Best config:\", best.config)\n",
    "\n",
    "    best_config = best.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829f54c",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_RAYTUNE:\n",
    "    model, optimizer, criterion = build_model(1e-3, num_classes)\n",
    "    \n",
    "    epochs = 5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc     = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e2e9f",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_RAYTUNE:\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(\"\\n=== Test Results ===\")\n",
    "    print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
