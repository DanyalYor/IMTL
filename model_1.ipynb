{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f254d9",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba804f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995acc7e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pathlib\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855f694",
   "metadata": {},
   "source": [
    "# Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5303d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path OK.\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = pathlib.Path(r\"data\\archive\\food-101\\food-101\")\n",
    "IMAGE_DIR = pathlib.Path(\"data/archive/food-101/food-101/images\")\n",
    "\n",
    "#DATA_ROOT = pathlib.Path(r\"E:\\\\food-101\\\\food-101\")\n",
    "#IMAGE_DIR = pathlib.Path(\"E:\\\\food-101\\\\food-101\\\\images\")\n",
    "\n",
    "if not IMAGE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Missing dataset folder: {IMAGE_DIR}\")\n",
    "\n",
    "print(\"Dataset path OK.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390e614",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39da1ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 101000\n",
      "Classes: 101\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(IMAGE_DIR, transform=train_transform, allow_empty=True)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Total images:\", len(full_dataset))\n",
    "print(\"Classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b8e5b",
   "metadata": {},
   "source": [
    "# Split data into sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c030d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(full_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c017e24",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b15b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds.dataset.transform = test_transform\n",
    "test_ds.dataset.transform = test_transform\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe28599",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326e55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "model = efficientnet_b0(weights=weights)\n",
    "\n",
    "# Replace classifier head\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b5fc1",
   "metadata": {},
   "source": [
    "## Initialize a W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48efe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    }
   ],
   "source": [
    "# W&B init\n",
    "wandb.login()  # will prompt you the first time in this environment\n",
    "\n",
    "wandb_config = {\n",
    "    \"model_name\": \"efficientnet_b0\",\n",
    "    \"img_size\": img_size,\n",
    "    \"batch_size\": 32,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"train_size\": len(train_ds),\n",
    "    \"val_size\": len(val_ds),\n",
    "    \"test_size\": len(test_ds),\n",
    "    \"num_classes\": num_classes,\n",
    "}\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"food101-efficientnet\",\n",
    "    config=wandb_config,\n",
    "    name=\"efficientnet_b0_food101_run_1\",  # you can change this per run\n",
    ")\n",
    "\n",
    "wandb.watch(model, log=\"all\", log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b776ffe",
   "metadata": {},
   "source": [
    "# Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b57a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, epoch, log_interval=100):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch}\", leave=False)\n",
    "\n",
    "    for batch_idx, (imgs, labels) in enumerate(pbar):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        avg_loss_so_far = total_loss / total\n",
    "        avg_acc_so_far = correct / total\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{avg_loss_so_far:.4f}\",\n",
    "            \"acc\": f\"{100 * avg_acc_so_far:.2f}%\"\n",
    "        })\n",
    "\n",
    "        # Optional: batch-level logging to W&B\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"batch/train_loss\": loss.item(),\n",
    "                    \"batch/lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                    \"epoch\": epoch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc = correct / total\n",
    "\n",
    "    # Epoch-level logging to W&B\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"epoch/train_loss\": avg_loss,\n",
    "            \"epoch/train_accuracy\": avg_acc,\n",
    "            \"epoch/train_error_rate\": 1 - avg_acc,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device, epoch=None, split=\"val\"):\n",
    "    \"\"\"\n",
    "    Generic evaluation for val/test.\n",
    "    split: \"val\" or \"test\" (used in W&B metric names).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    desc = f\"Evaluating ({split})\"\n",
    "    if epoch is not None:\n",
    "        desc += f\" Epoch {epoch}\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=desc, leave=False)\n",
    "\n",
    "        for imgs, labels in pbar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            avg_loss_so_far = total_loss / total\n",
    "            avg_acc_so_far = correct / total\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{avg_loss_so_far:.4f}\",\n",
    "                \"acc\": f\"{100 * avg_acc_so_far:.2f}%\"\n",
    "            })\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc = correct / total\n",
    "\n",
    "    # Log to W&B if epoch is known (for val) or just once (for test)\n",
    "    metric_prefix = f\"{split}\"\n",
    "    log_data = {\n",
    "        f\"{metric_prefix}/loss\": avg_loss,\n",
    "        f\"{metric_prefix}/accuracy\": avg_acc,\n",
    "        f\"{metric_prefix}/error_rate\": 1 - avg_acc,\n",
    "    }\n",
    "    if epoch is not None:\n",
    "        log_data[\"epoch\"] = epoch\n",
    "\n",
    "    wandb.log(log_data)\n",
    "\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74189d2",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bd15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1/5 Diagnostics ---\n",
      "Using device: cuda\n",
      "Model param device: cuda:0\n",
      "Allocated: 87.54541015625 MB\n",
      "Reserved: 662.0 MB\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  Train Loss: 2.5606, Acc: 0.4107\n",
      "  Val   Loss: 2.0274, Acc: 0.5018\n",
      "\n",
      "--- Epoch 2/5 Diagnostics ---\n",
      "Using device: cuda\n",
      "Model param device: cuda:0\n",
      "Allocated: 89.0263671875 MB\n",
      "Reserved: 668.0 MB\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "  Train Loss: 2.0194, Acc: 0.5044\n",
      "  Val   Loss: 1.9290, Acc: 0.5244\n",
      "\n",
      "--- Epoch 3/5 Diagnostics ---\n",
      "Using device: cuda\n",
      "Model param device: cuda:0\n",
      "Allocated: 89.0263671875 MB\n",
      "Reserved: 668.0 MB\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "  Train Loss: 1.9219, Acc: 0.5213\n",
      "  Val   Loss: 1.9018, Acc: 0.5263\n",
      "\n",
      "--- Epoch 4/5 Diagnostics ---\n",
      "Using device: cuda\n",
      "Model param device: cuda:0\n",
      "Allocated: 89.0263671875 MB\n",
      "Reserved: 668.0 MB\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "  Train Loss: 1.8626, Acc: 0.5354\n",
      "  Val   Loss: 1.8853, Acc: 0.5320\n",
      "\n",
      "--- Epoch 5/5 Diagnostics ---\n",
      "Using device: cuda\n",
      "Model param device: cuda:0\n",
      "Allocated: 89.0263671875 MB\n",
      "Reserved: 668.0 MB\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "  Train Loss: 1.8307, Acc: 0.5406\n",
      "  Val   Loss: 1.8868, Acc: 0.5330\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # ---- Debug: hardware info ----\n",
    "    print(f\"\\n--- Epoch {epoch}/{epochs} Diagnostics ---\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Check model parameters\n",
    "    first_param = next(model.parameters())\n",
    "    print(\"Model param device:\", first_param.device)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        print(\"Allocated:\", torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
    "        print(\"Reserved:\", torch.cuda.memory_reserved() / 1024**2, \"MB\")\n",
    "\n",
    "    print(\"-------------------------------------------\\n\")\n",
    "\n",
    "    # ---- Training ----\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device, epoch\n",
    "    )\n",
    "\n",
    "    # ---- Validation ----\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model, val_loader, criterion, device, epoch=epoch, split=\"val\"\n",
    "    )\n",
    "\n",
    "    # ---- Epoch Summary ----\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107677e",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2920648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Results ===\n",
      "Test Loss:     1.8994\n",
      "Test Accuracy: 0.5361\n",
      "====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(\n",
    "    model, test_loader, criterion, device, epoch=None, split=\"test\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Test Results ===\")\n",
    "print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-env (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
